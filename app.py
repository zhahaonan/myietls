import os
import json
import re
import time
import tempfile
import uvicorn
from pathlib import Path
from typing import Dict, Any, List, Optional, Literal
from fastapi import FastAPI, File, UploadFile, Form, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse, Response
from pydantic import BaseModel


# Load environment variables
from dotenv import load_dotenv
load_dotenv()

# åˆå§‹åŒ–FastAPIåº”ç”¨
fastapi_app = FastAPI(title="MyIELTS Voice API")

# æ·»åŠ CORSä¸­é—´ä»¶
fastapi_app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# APIå¯†é’¥é…ç½®
API_KEY = os.getenv("API_KEY") or os.getenv("GEMINI_API_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
DASHSCOPE_API_KEY = os.getenv("DASHSCOPE_API_KEY")


# å»¶è¿Ÿåˆå§‹åŒ–AIå¼•æ“ï¼Œé¿å…åœ¨ç¼ºå°‘ä¾èµ–æˆ–APIå¯†é’¥æ—¶å´©æºƒ
camel_engine = None
rag_module = None
ALLOWED_BANDS = {"5.5", "6", "6.5", "7", "7.5", "8"}

try:
    from engine.camel_agents import CamelIELTSAgent
    camel_engine = CamelIELTSAgent(api_key=API_KEY)
except Exception as e:
    print(f"è­¦å‘Š: Camelä»£ç†åˆå§‹åŒ–å¤±è´¥: {e}")

try:
    from engine.rag import AgenticRAG
    rag_module = AgenticRAG()
except Exception as e:
    print(f"è­¦å‘Š: RAGæ¨¡å—åˆå§‹åŒ–å¤±è´¥: {e}")

try:
    from engine.p1_service import ALLOWED_BANDS, generate_p1_answer
except Exception as e:
    print(f"è­¦å‘Š: P1æœåŠ¡å¯¼å…¥å¤±è´¥: {e}")
    def generate_p1_answer(**kwargs):
        return "æœåŠ¡æš‚ä¸å¯ç”¨"

try:
    from engine.tts import synthesize_speech
except Exception as e:
    print(f"è­¦å‘Š: TTSæœåŠ¡å¯¼å…¥å¤±è´¥: {e}")
    def synthesize_speech(**kwargs):
        raise RuntimeError("TTSæœåŠ¡ä¸å¯ç”¨")

try:
    from engine import openai_client
except Exception as e:
    print(f"è­¦å‘Š: openai_clientå¯¼å…¥å¤±è´¥: {e}")
    openai_client = None


# è¯·æ±‚æ¨¡å‹å®šä¹‰
class EvaluationRequest(BaseModel):
    question: str
    level: str
    part: str = "P1"


class P1ResponseRequest(BaseModel):
    question: str
    band: str
    profile: Dict[str, Any] = {}


class TTSRequest(BaseModel):
    text: str
    voice: str = None
    audio_format: str = "wav"


# APIè·¯ç”±å®šä¹‰
@fastapi_app.post("/api/process_evaluation")
async def api_process_evaluation(
    question: str = Form(...),
    level: str = Form(...),
    part: str = Form("P1"),
    audio_file: UploadFile = File(...)
):
    """å¤„ç†IELTSå£è¯­è¯„ä¼°APIæ¥å£ï¼Œæ¥æ”¶ä¸Šä¼ çš„éŸ³é¢‘æ–‡ä»¶"""
    if not audio_file:
        return {"error": "è¯·ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶ã€‚"}
    
    if not question:
        return {"error": "è¯·è¾“å…¥é—®é¢˜ã€‚"}
    
    if not level:
        return {"error": "è¯·é€‰æ‹©ç›®æ ‡åˆ†æ•°ã€‚"}
    
    if camel_engine is None:
        return {"error": "AIå¼•æ“æœªåˆå§‹åŒ–ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥é…ç½®ã€‚"}

    try:
        # ä¿å­˜ä¸Šä¼ çš„éŸ³é¢‘æ–‡ä»¶åˆ°ä¸´æ—¶ä½ç½®
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as temp_file:
            temp_file.write(await audio_file.read())
            temp_filename = temp_file.name

        # è¯»å–éŸ³é¢‘æ–‡ä»¶
        with open(temp_filename, 'rb') as f:
            audio_bytes = f.read()

        # æ‰§è¡Œè¯„ä¼°
        result = camel_engine.run_roleplay_evaluation(
            audio_bytes=audio_bytes,
            question=question,
            target_level=level,
            part=part
        )

        # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
        os.unlink(temp_filename)

        return result

    except Exception as e:
        return {"error": f"å¤„ç†å‡ºé”™: {str(e)}"}


@fastapi_app.post("/api/generate_p1_response")
async def api_generate_p1_response(request: P1ResponseRequest):
    """ç”ŸæˆPart 1å›ç­”APIæ¥å£"""
    question = request.question
    band = request.band
    profile = request.profile

    if not question:
        return {"error": "è¯·è¾“å…¥é—®é¢˜ã€‚"}

    if not band:
        return {"error": "è¯·é€‰æ‹©ç›®æ ‡åˆ†æ•°ã€‚"}

    if band not in ALLOWED_BANDS:
        return {"error": f"æ— æ•ˆçš„ç›®æ ‡åˆ†æ•°ã€‚å…è®¸çš„åˆ†æ•°: {sorted(ALLOWED_BANDS)}"}

    try:
        content = generate_p1_answer(question=question, band=band, profile=profile)
        return {"content": content}
    except Exception as e:
        return {"error": f"ç”Ÿæˆå›ç­”å‡ºé”™: {str(e)}"}


@fastapi_app.post("/api/text_to_speech")
async def api_text_to_speech(request: TTSRequest):
    """æ–‡å­—è½¬è¯­éŸ³APIæ¥å£"""
    text = request.text
    voice = request.voice
    audio_format = request.audio_format

    if not text:
        return {"error": "è¯·è¾“å…¥è¦è½¬æ¢çš„æ–‡å­—ã€‚"}

    if not DASHSCOPE_API_KEY:
        return {"error": "ç¼ºå°‘DASHSCOPE_API_KEYç¯å¢ƒå˜é‡ã€‚"}

    try:
        audio_bytes, content_type = synthesize_speech(
            text=text,
            voice=voice,
            audio_format=audio_format
        )

        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶ä¿å­˜éŸ³é¢‘
        with tempfile.NamedTemporaryFile(delete=False, suffix=f".{audio_format}") as temp_file:
            temp_file.write(audio_bytes)
            temp_filename = temp_file.name

        return {"audio_file": temp_filename, "message": "è¯­éŸ³åˆæˆæˆåŠŸã€‚"}
    except Exception as e:
        return {"error": f"è¯­éŸ³åˆæˆå‡ºé”™: {str(e)}"}


@fastapi_app.get("/api/question_bank")
async def api_get_question_bank():
    """è·å–é¢˜åº“APIæ¥å£"""
    if rag_module is None:
        return {"error": "RAGæ¨¡å—æœªåˆå§‹åŒ–ï¼Œè¯·æ£€æŸ¥é…ç½®ã€‚"}

    try:
        questions = rag_module.get_question_context("all")
        return {"questions": questions}
    except Exception as e:
        return {"error": f"è·å–é¢˜åº“å‡ºé”™: {str(e)}"}


@fastapi_app.get("/api/health")
async def health_check():
    """APIå¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy", 
        "camel_engine": camel_engine is not None, 
        "rag_module": rag_module is not None,
        "api_keys_configured": bool(API_KEY and DASHSCOPE_API_KEY)
    }


class PolishRequest(BaseModel):
    draft: str
    context: str = ""
    studentLevel: str = "6.0-6.5"
    targetBand: float = 6.5
    part: str = "P1"
    isDirectExample: bool = False


class TranslateWordRequest(BaseModel):
    word: str


@fastapi_app.post("/api/polish")
async def polish_draft(req: PolishRequest):
    """Polish a draft answer using the LLM, return English + Chinese + imagePrompt."""
    if openai_client is None:
        return {"en": req.draft, "cn": "(ç¿»è¯‘æš‚ä¸å¯ç”¨)", "imagePrompt": ""}

    prompt = f"""Student Level: {req.studentLevel}, Target Band: {req.targetBand}.
Type: Part {req.part}.
{req.context}
Draft: "{req.draft}".

Task:
1. {"Keep this text exactly as provided (do not refine it)." if req.isDirectExample else "Refine the draft into a Band 8.5 response."}
2. Translate the English text to Chinese.
3. Create a short image description for the scene.
4. Return JSON with keys: en, cn, imagePrompt"""

    try:
        raw = openai_client.chat(
            messages=[
                {"role": "system", "content": "You are an IELTS speaking coach. Always respond with valid JSON containing keys: en, cn, imagePrompt."},
                {"role": "user", "content": prompt},
            ],
            temperature=0.7,
        )
        result = json.loads(raw)
        return {"en": result.get("en", req.draft), "cn": result.get("cn", ""), "imagePrompt": result.get("imagePrompt", "")}
    except (json.JSONDecodeError, RuntimeError):
        return {"en": req.draft, "cn": "(ç¿»è¯‘æš‚ä¸å¯ç”¨)", "imagePrompt": ""}


@fastapi_app.post("/api/translate_word")
async def translate_word(req: TranslateWordRequest):
    """Translate an English word/phrase to Chinese with an emoji."""
    if openai_client is None:
        return {"translation": req.word, "emoji": "ğŸ“"}

    prompt = f'Translate the English word/phrase "{req.word}" to Chinese contextually as used in IELTS. Also provide 1 relevant emoji. Return JSON {{ "translation": "...", "emoji": "..." }}'

    try:
        raw = openai_client.chat(
            messages=[
                {"role": "system", "content": "Always respond with valid JSON containing keys: translation, emoji."},
                {"role": "user", "content": prompt},
            ],
            temperature=0.3,
        )
        result = json.loads(raw)
        return {"translation": result.get("translation", ""), "emoji": result.get("emoji", "")}
    except (json.JSONDecodeError, RuntimeError):
        return {"translation": req.word, "emoji": "ğŸ“"}


# ============================================================
# /v1 ç³»åˆ—ç«¯ç‚¹ - å‰ç«¯ apiService.ts å’Œ TTSProvider.ts æ‰€éœ€
# ============================================================

class ChatMessage(BaseModel):
    role: str
    content: str

class ChatCompletionRequest(BaseModel):
    model: str = "myielts-multi-agent"
    messages: List[ChatMessage]
    metadata: Optional[Dict[str, Any]] = None

class SpeechRequest(BaseModel):
    input: str
    voice: Optional[str] = None
    format: Literal["wav", "mp3"] = "wav"
    model: Optional[str] = None


@fastapi_app.post("/v1/ielts/evaluate")
async def ielts_evaluate(
    audio: Optional[UploadFile] = File(None),
    part: str = Form("P1"),
    question: str = Form(""),
    level: str = Form("6.0-6.5")
):
    """IELTSè¯„ä¼°ç«¯ç‚¹ï¼Œä¸å‰ç«¯apiService.tsçš„callIELTSAgentå¯¹æ¥ã€‚"""
    if not audio:
        raise HTTPException(status_code=400, detail="No audio file provided.")

    if camel_engine is None:
        raise HTTPException(status_code=503, detail="AIå¼•æ“æœªåˆå§‹åŒ–ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥é…ç½®ã€‚")

    try:
        audio_bytes = await audio.read()
        result = await camel_engine.run_roleplay_evaluation(
            audio_bytes=audio_bytes,
            question=question,
            target_level=level,
            part=part
        )
        return {
            "id": f"chatcmpl-{int(time.time())}",
            "object": "chat.completion",
            "created": int(time.time()),
            "model": "myielts-multi-agent",
            "choices": [{
                "index": 0,
                "message": {
                    "role": "assistant",
                    "content": result["feedback"],
                    "metadata": {
                        "transcription": result["transcription"],
                        "scores": result["scores"],
                        "agent_thoughts": result["agent_thoughts"],
                        "xp_reward": result["xpReward"]
                    }
                },
                "finish_reason": "stop"
            }]
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@fastapi_app.post("/v1/chat/completions")
async def chat_completions(payload: ChatCompletionRequest):
    """OpenAIé£æ ¼çš„chatç«¯ç‚¹ï¼Œä¸å‰ç«¯generateP1Answerå¯¹æ¥ã€‚"""
    last_user_message = ""
    for message in reversed(payload.messages):
        if message.role == "user":
            last_user_message = message.content
            break

    metadata = payload.metadata or {}

    if metadata.get("task") == "p1_answer":
        band = str(metadata.get("band", "")).strip()
        if band not in ALLOWED_BANDS:
            raise HTTPException(status_code=400, detail=f"Invalid band '{band}'.")
        question = str(metadata.get("question") or last_user_message).strip()
        if not question:
            raise HTTPException(status_code=400, detail="Missing question.")
        profile = metadata.get("profile") or {}
        content = generate_p1_answer(question=question, band=band, profile=profile)
    else:
        if openai_client is None:
            content = f"LLM unavailable\nFallback: {last_user_message or 'Sorry.'}"
        else:
            try:
                content = openai_client.chat(
                    messages=[{"role": m.role, "content": m.content} for m in payload.messages]
                )
            except RuntimeError:
                content = f"LLM unavailable\nFallback: {last_user_message or 'Sorry.'}"

    return {
        "id": f"chatcmpl-{int(time.time())}",
        "object": "chat.completion",
        "created": int(time.time()),
        "model": os.getenv("OPENAI_MODEL", payload.model),
        "choices": [{
            "index": 0,
            "message": {"role": "assistant", "content": content},
            "finish_reason": "stop"
        }]
    }


@fastapi_app.post("/v1/audio/speech")
async def audio_speech(payload: SpeechRequest):
    """TTSç«¯ç‚¹ï¼Œä¸å‰ç«¯TTSProvider.tså¯¹æ¥ã€‚"""
    text = payload.input.strip()
    if not text:
        raise HTTPException(status_code=400, detail="Field 'input' cannot be empty.")

    try:
        audio_bytes, content_type = synthesize_speech(
            text=text,
            voice=payload.voice,
            audio_format=payload.format,
            model=payload.model,
        )
    except RuntimeError as exc:
        message = str(exc)
        status_code = 502
        if "Missing DASHSCOPE_API_KEY" in message:
            status_code = 500
        if "Unsupported format" in message:
            status_code = 400
        raise HTTPException(status_code=status_code, detail=message)

    return Response(content=audio_bytes, media_type=content_type)


# é…ç½®å‰ç«¯é™æ€æ–‡ä»¶æœåŠ¡
frontend_dist_path = Path(__file__).parent / "dist"
if frontend_dist_path.exists():
    assets_dir = frontend_dist_path / "assets"
    if assets_dir.exists():
        fastapi_app.mount("/assets", StaticFiles(directory=str(assets_dir)), name="assets")

    @fastapi_app.get("/")
    async def serve_frontend():
        return FileResponse(str(frontend_dist_path / "index.html"))

    @fastapi_app.get("/app")
    async def serve_app():
        return FileResponse(str(frontend_dist_path / "index.html"))
else:
    @fastapi_app.get("/")
    async def root():
        return {
            "message": "MyIELTS Voice API æœåŠ¡è¿è¡Œä¸­",
            "endpoints": [
                "/api/health",
                "/api/process_evaluation",
                "/api/generate_p1_response", 
                "/api/text_to_speech",
                "/api/question_bank"
            ],
            "frontend": "Reactå‰ç«¯æœªæ‰¾åˆ°ï¼Œéœ€è¦å…ˆæ„å»ºå‰ç«¯é¡¹ç›®"
        }


if __name__ == "__main__":
    uvicorn.run(
        fastapi_app,
        host="0.0.0.0",
        port=7860,
        log_level="info"
    )
